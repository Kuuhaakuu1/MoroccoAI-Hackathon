{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'do', 'love', 'my', 'ma', 'and', 'pa', ',', 'but', 'does', 'that', 'mean', 'I', 'should', 'marry', 'my', 'sister', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')  # uncomment if you haven't downloaded punkt yet\n",
    "\n",
    "sentence = \"\"\"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\"\"\n",
    "new_sentence = \"\"\"I do love my ma and pa, but does that mean I should marry my sister?\"\"\"\n",
    "# tokens = nltk.word_tokenize(sentence)\n",
    "tokens = nltk.word_tokenize(new_sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('do', 'VBP'), ('love', 'VB'), ('my', 'PRP$'), ('ma', 'NN'), ('and', 'CC'), ('pa', 'NN'), (',', ','), ('but', 'CC'), ('does', 'VBZ'), ('that', 'IN'), ('mean', 'VB'), ('I', 'PRP'), ('should', 'MD'), ('marry', 'VB'), ('my', 'PRP$'), ('sister', 'NN'), ('?', '.')]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('averaged_perceptron_tagger') # uncomment if you haven't downloaded averaged_perceptron_tagger yet\n",
    "\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)\n",
    "print(type(tagged))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,784.0,120.0\" width=\"784px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"5.10204%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"2.55102%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.10204%\" x=\"5.10204%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">do</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.65306%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"10.2041%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">love</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.2653%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"16.3265%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.3878%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.08163%\" x=\"22.449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ma</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"24.4898%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.10204%\" x=\"26.5306%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.0816%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.08163%\" x=\"31.6327%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">pa</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.6735%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"35.7143%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.2449%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.10204%\" x=\"38.7755%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">but</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.3265%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"43.8776%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">does</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBZ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.9388%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">that</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.0612%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"56.1224%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">mean</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.1837%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.10204%\" x=\"62.2449%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">I</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7959%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.16327%\" x=\"67.3469%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">should</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.4286%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.14286%\" x=\"75.5102%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">marry</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.0816%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.12245%\" x=\"82.6531%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">my</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.7143%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.16327%\" x=\"88.7755%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">sister</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.8571%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.06122%\" x=\"96.9388%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">?</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.4694%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('I', 'PRP'), ('do', 'VBP'), ('love', 'VB'), ('my', 'PRP$'), ('ma', 'NN'), ('and', 'CC'), ('pa', 'NN'), (',', ','), ('but', 'CC'), ('does', 'VBZ'), ('that', 'IN'), ('mean', 'VB'), ('I', 'PRP'), ('should', 'MD'), ('marry', 'VB'), ('my', 'PRP$'), ('sister', 'NN'), ('?', '.')])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('maxent_ne_chunker') # uncomment if you haven't downloaded maxent_ne_chunker yet\n",
    "#nltk.download('words') # uncomment if you haven't downloaded words yet\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "\n",
    "entities\n",
    "# print(type(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "['I', 'do', 'love', 'my', 'ma', 'and', 'pa', ',', 'but', 'does', 'that', 'mean', 'I', 'should', 'marry', 'my', 'sister', '?']\n",
      "['i', 'do', 'love', 'my', 'ma', 'and', 'pa', ',', 'but', 'doe', 'that', 'mean', 'i', 'should', 'marri', 'my', 'sister', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "# nltk.download('punkt')  # uncomment if you haven't downloaded punkt yet\n",
    "# nltk.download('averaged_perceptron_tagger')  # uncomment if you haven't downloaded averaged_perceptron_tagger yet\n",
    "# nltk.download('maxent_ne_chunker')  # uncomment if you haven't downloaded maxent_ne_chunker yet\n",
    "# nltk.download('words')  # uncomment if you haven't downloaded words yet\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "word = \"running\"\n",
    "stemmed_word = stemmer.stem(word)\n",
    "print(stemmed_word)\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in tokens]\n",
    "print(tokens)\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "['I', 'do', 'love', 'my', 'ma', 'and', 'pa', ',', 'but', 'does', 'that', 'mean', 'I', 'should', 'marry', 'my', 'sister', '?']\n",
      "['i', 'do', 'lov', 'my', 'ma', 'and', 'pa', ',', 'but', 'doe', 'that', 'mean', 'i', 'should', 'marry', 'my', 'sist', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "word = \"running\"\n",
    "stemmed_word = stemmer.stem(word)\n",
    "print(stemmed_word)\n",
    "\n",
    "stemmed_words = [stemmer.stem(w) for w in tokens]\n",
    "print(tokens)\n",
    "print(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'each', 'yourself', 'further', 'we', 'he', 'whom', 'how', 'her', 'very', 'were', 'while', 'again', 'did', 'needn', \"wasn't\", \"haven't\", 'won', 'by', 'me', 'up', 'nor', 'this', 'down', 'during', 'who', 'no', 've', 'only', 'to', 'wouldn', 'being', 'all', 'about', 'hasn', 'doesn', 'been', 'weren', 'ourselves', 'yourselves', \"don't\", 'y', 'there', 'too', 'hadn', 'a', \"aren't\", 'or', 'out', \"hadn't\", 'an', \"you're\", 'so', \"shan't\", 'your', 'my', 'until', 'its', 'it', 'because', 'they', 'are', 'most', \"mustn't\", 'when', 'these', 'shouldn', \"that'll\", 'between', \"won't\", 'yours', 'against', 'then', 'that', 'in', 'be', 'you', \"you've\", 'with', 'at', 'aren', 'i', \"you'll\", 'than', \"you'd\", 'just', 'shan', \"should've\", 'those', 'but', 'his', 'through', 'hers', 'under', 'into', 'where', 'here', 'some', \"weren't\", 'isn', \"she's\", 'from', 'not', 'm', 'o', 'few', 'have', 'such', 'having', 'above', 'didn', 'ain', \"hasn't\", 'and', 'their', 'of', 'more', 'own', 'will', 'was', 'after', 'on', 'our', 'the', 'any', 'other', 'does', 'him', 'ma', 'what', 'has', 'for', 'them', 'll', 'am', \"couldn't\", 'both', 'do', 'couldn', 'now', \"doesn't\", 'myself', \"wouldn't\", 'before', 'once', 'mustn', 'theirs', 'below', 'can', 'herself', 'd', 'mightn', 'should', 're', 'ours', 'why', \"needn't\", 'if', 'which', 'haven', 'themselves', 'himself', 'had', 'don', \"isn't\", 'itself', 'is', \"didn't\", \"shouldn't\", \"it's\", 'as', 's', 'doing', \"mightn't\", 'off', 't', 'over', 'wasn', 'same', 'she'}\n",
      "Classification: sentiment\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Preprocess the sentence\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "# tokens = word_tokenize(sentence.lower())\n",
    "filtered_tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "\n",
    "# Define the features\n",
    "features = {token: True for token in filtered_tokens}\n",
    "\n",
    "# Define the training data\n",
    "training_data = [(features, 'sentiment')]  # Replace `label` with the actual label for your training data\n",
    "\n",
    "# Train the classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_data)\n",
    "\n",
    "# Classify the sentence\n",
    "classification = classifier.classify(features)\n",
    "print(\"Classification:\", classification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
